{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f05c35e-e657-4aa0-9ef1-d77535cc5d0f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:34.343287Z",
          "iopub.status.busy": "2023-09-02T11:06:34.342929Z",
          "iopub.status.idle": "2023-09-02T11:06:37.181875Z",
          "shell.execute_reply": "2023-09-02T11:06:37.181169Z",
          "shell.execute_reply.started": "2023-09-02T11:06:34.343265Z"
        },
        "tags": [],
        "id": "7f05c35e-e657-4aa0-9ef1-d77535cc5d0f",
        "outputId": "a0d73bbc-da7b-40a7-a6bd-4e0d52f72cc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (2.0.1)\n",
            "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (3.12.3)\n",
            "Requirement already satisfied: typing-extensions in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.8.0)\n",
            "Requirement already satisfied: wheel in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.41.0)\n",
            "Requirement already satisfied: cmake in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from triton==2.0.0->torch) (3.27.2)\n",
            "Requirement already satisfied: lit in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70eaf211-f894-4e78-aecc-830abbec13d4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:37.183647Z",
          "iopub.status.busy": "2023-09-02T11:06:37.183343Z",
          "iopub.status.idle": "2023-09-02T11:06:38.452933Z",
          "shell.execute_reply": "2023-09-02T11:06:38.452335Z",
          "shell.execute_reply.started": "2023-09-02T11:06:37.183625Z"
        },
        "tags": [],
        "id": "70eaf211-f894-4e78-aecc-830abbec13d4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "device = torch.device(\"cpu\")  # or \"cpu\" if you want to use CPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a9368eb-1a19-4071-b019-1235f16c2a73",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:38.454128Z",
          "iopub.status.busy": "2023-09-02T11:06:38.453801Z",
          "iopub.status.idle": "2023-09-02T11:06:38.458013Z",
          "shell.execute_reply": "2023-09-02T11:06:38.457289Z",
          "shell.execute_reply.started": "2023-09-02T11:06:38.454108Z"
        },
        "tags": [],
        "id": "0a9368eb-1a19-4071-b019-1235f16c2a73",
        "outputId": "d3704604-b15c-49d8-b455-fcefb1f69443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/jovyan/workspace\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5389b6e3-14f5-4c85-b0f5-4f9fa42c5a20",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:38.459123Z",
          "iopub.status.busy": "2023-09-02T11:06:38.458868Z",
          "iopub.status.idle": "2023-09-02T11:06:38.521229Z",
          "shell.execute_reply": "2023-09-02T11:06:38.520663Z",
          "shell.execute_reply.started": "2023-09-02T11:06:38.459104Z"
        },
        "tags": [],
        "id": "5389b6e3-14f5-4c85-b0f5-4f9fa42c5a20",
        "outputId": "372c7eda-9f9b-4c50-a0fb-15c0a25fd1d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20302"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Give the path for validation data\n",
        "path = Path('/home/jovyan/workspace/squad/dev-v2.0.json')\n",
        "\n",
        "# Open .json file\n",
        "with open(path, 'rb') as f:\n",
        "    squad_dict = json.load(f)\n",
        "\n",
        "texts = []\n",
        "queries = []\n",
        "answers = []\n",
        "\n",
        "for group in squad_dict['data']:\n",
        "    for passage in group['paragraphs']:\n",
        "        context = passage['context']\n",
        "        for qa in passage['qas']:\n",
        "            question = qa['question']\n",
        "            for answer in qa['answers']:\n",
        "                texts.append(context)\n",
        "                queries.append(question)\n",
        "                answers.append(answer)\n",
        "\n",
        "val_texts, val_queries, val_answers = texts, queries, answers\n",
        "len(val_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc1a06d5-c5da-4f48-94e9-8c060b52f118",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:38.523081Z",
          "iopub.status.busy": "2023-09-02T11:06:38.522809Z",
          "iopub.status.idle": "2023-09-02T11:06:38.538747Z",
          "shell.execute_reply": "2023-09-02T11:06:38.538201Z",
          "shell.execute_reply.started": "2023-09-02T11:06:38.523061Z"
        },
        "tags": [],
        "id": "dc1a06d5-c5da-4f48-94e9-8c060b52f118"
      },
      "outputs": [],
      "source": [
        "for answer, text in zip(val_answers, val_texts):\n",
        "    real_answer = answer['text']\n",
        "    start_idx = answer['answer_start']\n",
        "    # Get the real end index\n",
        "    end_idx = start_idx + len(real_answer)\n",
        "\n",
        "    # Deal with the problem of 1 or 2 more characters\n",
        "    if text[start_idx:end_idx] == real_answer:\n",
        "        answer['answer_end'] = end_idx\n",
        "    # When the real answer is more by one character\n",
        "    elif text[start_idx-1:end_idx-1] == real_answer:\n",
        "        answer['answer_start'] = start_idx - 1\n",
        "        answer['answer_end'] = end_idx - 1\n",
        "    # When the real answer is more by two characters\n",
        "    elif text[start_idx-2:end_idx-2] == real_answer:\n",
        "        answer['answer_start'] = start_idx - 2\n",
        "        answer['answer_end'] = end_idx - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c7e536-214d-4fc1-a613-73a9118e1b99",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:38.539728Z",
          "iopub.status.busy": "2023-09-02T11:06:38.539481Z",
          "iopub.status.idle": "2023-09-02T11:06:41.318648Z",
          "shell.execute_reply": "2023-09-02T11:06:41.317881Z",
          "shell.execute_reply.started": "2023-09-02T11:06:38.539709Z"
        },
        "tags": [],
        "id": "10c7e536-214d-4fc1-a613-73a9118e1b99",
        "outputId": "cccbf00a-dc10-4c50-f0c1-f9a7a2d346bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (4.32.1)\n",
            "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (3.12.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (2023.8.8)\n",
            "Requirement already satisfied: requests in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2022.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c09e76-c7d7-4276-8ffe-cf7e824f3737",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:41.319994Z",
          "iopub.status.busy": "2023-09-02T11:06:41.319719Z",
          "iopub.status.idle": "2023-09-02T11:06:41.907028Z",
          "shell.execute_reply": "2023-09-02T11:06:41.906387Z",
          "shell.execute_reply.started": "2023-09-02T11:06:41.319973Z"
        },
        "tags": [],
        "id": "94c09e76-c7d7-4276-8ffe-cf7e824f3737"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('deepset/roberta-base-squad2')\n",
        "\n",
        "# Prepare input\n",
        "question = \"Why is model conversion important?\"\n",
        "context = \"The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.\"\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer(question, context, return_tensors='pt', truncation=True)\n",
        "\n",
        "# Move tensors to the appropriate device\n",
        "\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d32bc06c-23ef-4355-97bb-b7628694e1f2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:41.908340Z",
          "iopub.status.busy": "2023-09-02T11:06:41.907918Z",
          "iopub.status.idle": "2023-09-02T11:06:43.632029Z",
          "shell.execute_reply": "2023-09-02T11:06:43.631465Z",
          "shell.execute_reply.started": "2023-09-02T11:06:41.908319Z"
        },
        "tags": [],
        "id": "d32bc06c-23ef-4355-97bb-b7628694e1f2",
        "outputId": "d5890955-c811-4638-cc19-8f3067fc6720"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RobertaForQuestionAnswering(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model_path = \"/home/jovyan/V1_model\"\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "model.to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eefccc7e-3f90-41c1-8b83-0b01725ba67b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:43.633207Z",
          "iopub.status.busy": "2023-09-02T11:06:43.632883Z",
          "iopub.status.idle": "2023-09-02T11:06:46.733538Z",
          "shell.execute_reply": "2023-09-02T11:06:46.732897Z",
          "shell.execute_reply.started": "2023-09-02T11:06:43.633186Z"
        },
        "tags": [],
        "id": "eefccc7e-3f90-41c1-8b83-0b01725ba67b"
      },
      "outputs": [],
      "source": [
        "val_encodings = tokenizer(val_texts, val_queries, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ee9c9d6-c83a-46e7-8e1b-e06370a76e44",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:46.734731Z",
          "iopub.status.busy": "2023-09-02T11:06:46.734442Z",
          "iopub.status.idle": "2023-09-02T11:06:46.787097Z",
          "shell.execute_reply": "2023-09-02T11:06:46.786516Z",
          "shell.execute_reply.started": "2023-09-02T11:06:46.734712Z"
        },
        "tags": [],
        "id": "9ee9c9d6-c83a-46e7-8e1b-e06370a76e44",
        "outputId": "35c74e00-7d6d-4b28-ff4b-9e888f189fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n"
          ]
        }
      ],
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "  start_positions = []\n",
        "  end_positions = []\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  for i in range(len(answers)):\n",
        "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
        "\n",
        "    # if start position is None, the answer passage has been truncated\n",
        "    if start_positions[-1] is None:\n",
        "      start_positions[-1] = tokenizer.model_max_length\n",
        "\n",
        "    # if end position is None, the 'char_to_token' function points to the space after the correct token, so add - 1\n",
        "    if end_positions[-1] is None:\n",
        "      end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - 1)\n",
        "      # if end position is still None the answer passage has been truncated\n",
        "      if end_positions[-1] is None:\n",
        "        count += 1\n",
        "        end_positions[-1] = tokenizer.model_max_length\n",
        "\n",
        "  print(count)\n",
        "\n",
        "  # Update the data in dictionary\n",
        "  encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "\n",
        "add_token_positions(val_encodings, val_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b5f43c4-b128-42c2-9405-a2acd3c2af37",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:46.788169Z",
          "iopub.status.busy": "2023-09-02T11:06:46.787906Z",
          "iopub.status.idle": "2023-09-02T11:06:46.792184Z",
          "shell.execute_reply": "2023-09-02T11:06:46.791678Z",
          "shell.execute_reply.started": "2023-09-02T11:06:46.788151Z"
        },
        "tags": [],
        "id": "8b5f43c4-b128-42c2-9405-a2acd3c2af37"
      },
      "outputs": [],
      "source": [
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "val_dataset = SquadDataset(val_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd89121b-8b37-4843-afdf-13154b8921c8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:46.793206Z",
          "iopub.status.busy": "2023-09-02T11:06:46.792966Z",
          "iopub.status.idle": "2023-09-02T11:06:46.797254Z",
          "shell.execute_reply": "2023-09-02T11:06:46.796713Z",
          "shell.execute_reply.started": "2023-09-02T11:06:46.793189Z"
        },
        "tags": [],
        "id": "bd89121b-8b37-4843-afdf-13154b8921c8"
      },
      "outputs": [],
      "source": [
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b421c5-b9e5-4588-a1d9-2dd0fdefba0c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:46.798200Z",
          "iopub.status.busy": "2023-09-02T11:06:46.797956Z",
          "iopub.status.idle": "2023-09-02T11:06:46.803524Z",
          "shell.execute_reply": "2023-09-02T11:06:46.803027Z",
          "shell.execute_reply.started": "2023-09-02T11:06:46.798183Z"
        },
        "tags": [],
        "id": "b6b421c5-b9e5-4588-a1d9-2dd0fdefba0c"
      },
      "outputs": [],
      "source": [
        "# Initialize the model and optimizer\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model.to(device)\n",
        "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6b9ee97-4fc2-4e2f-8850-18744f2cb07c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:06:46.805769Z",
          "iopub.status.busy": "2023-09-02T11:06:46.805346Z",
          "iopub.status.idle": "2023-09-02T11:44:16.325087Z",
          "shell.execute_reply": "2023-09-02T11:44:16.324462Z",
          "shell.execute_reply.started": "2023-09-02T11:06:46.805751Z"
        },
        "tags": [],
        "id": "c6b9ee97-4fc2-4e2f-8850-18744f2cb07c",
        "outputId": "0ea7764c-0da9-46bb-c9f6-76db4647cc1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19302\n",
            "18302\n",
            "17302\n",
            "16302\n",
            "15302\n",
            "14302\n",
            "13302\n",
            "12302\n",
            "11302\n",
            "10302\n",
            "9302\n",
            "8302\n",
            "7302\n",
            "6302\n",
            "5302\n",
            "4302\n",
            "3302\n",
            "2302\n",
            "1302\n",
            "302\n",
            "Accuracy: 0.8867106688996158\n",
            "Exact Match: 0.5978721308245493\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
        "\n",
        "\n",
        "\n",
        "# Define the question answering pipeline\n",
        "\n",
        "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Get the answer\n",
        "\n",
        "pred = []\n",
        "ans = []\n",
        "c = 0\n",
        "total = 0\n",
        "for x, y, z in zip(val_texts, val_queries, val_answers):\n",
        " # Move question tensor to the device\n",
        "    answer = nlp(question=y, context=x)\n",
        "\n",
        "\n",
        "    total += 1\n",
        "    c += 1\n",
        "    pred.append(answer['answer'])  # prediction\n",
        "    ans.append(z['text'])\n",
        "\n",
        "    if c == 1000:\n",
        "        c = 0\n",
        "        emp = (len(val_texts) - total)\n",
        "        print(emp)\n",
        "\n",
        "\n",
        "# Print the answer\n",
        "accuracy = 0\n",
        "exact_match = 0\n",
        "\n",
        "for prediction, answer in zip(pred, ans):\n",
        "    if prediction == answer:\n",
        "        exact_match += 1\n",
        "    if prediction in answer or answer in prediction:\n",
        "        accuracy += 1\n",
        "\n",
        "accuracy = accuracy / len(pred)  # Calculate accuracy as a ratio\n",
        "exact_match = exact_match / len(pred)  # Calculate exact match as a ratio\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Exact Match:\", exact_match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14fd7c65-4068-4e44-b183-a588946c8e71",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-02T11:45:58.094968Z",
          "iopub.status.busy": "2023-09-02T11:45:58.094290Z",
          "iopub.status.idle": "2023-09-02T11:45:58.106636Z",
          "shell.execute_reply": "2023-09-02T11:45:58.106036Z",
          "shell.execute_reply.started": "2023-09-02T11:45:58.094942Z"
        },
        "tags": [],
        "id": "14fd7c65-4068-4e44-b183-a588946c8e71",
        "outputId": "3fc6d15c-8151-4ec5-b9f0-7f382e7274d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8867543449250763\n",
            "Exact Match: 0.5979015797522818\n"
          ]
        }
      ],
      "source": [
        "for prediction, answer in zip(pred, ans):\n",
        "    if prediction == answer:\n",
        "        exact_match += 1\n",
        "    if prediction in answer or answer in prediction:\n",
        "        accuracy += 1\n",
        "\n",
        "accuracy = accuracy / len(pred)  # Calculate accuracy as a ratio\n",
        "exact_match = exact_match / len(pred)  # Calculate exact match as a ratio\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Exact Match:\", exact_match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "131e68ac-752c-4a15-87d2-ae35c51a0c40",
      "metadata": {
        "id": "131e68ac-752c-4a15-87d2-ae35c51a0c40"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "saturn (Python 3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}